{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sarcasm Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvSOpprhjEOr"
      },
      "source": [
        "#Necessary packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.model_selection import cross_val_score as cvs\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.losses import MeanSquaredError as mse\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import confusion_matrix as cm\n",
        "from sklearn.metrics import precision_score, recall_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQIwYxaIjF-Z",
        "outputId": "075f7d49-bdcb-476f-f9a5-44cde3bea105"
      },
      "source": [
        "#Getting pathnames for each file in the input folder\n",
        "for dirname, _, filenames in os.walk('/content/Sarcasm_Headlines_Dataset_v2.json'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "#Function to parse data\n",
        "def parse_data(file):\n",
        "    for l in open(file,'r'):\n",
        "        yield json.loads(l)\n",
        "\n",
        "#Taking in the data in one of the json files (I'm using the slightly larger one)\n",
        "data = list(parse_data(\"/content/Sarcasm_Headlines_Dataset_v2.json\"))\n",
        "\n",
        "#Check 0-th index in our data\n",
        "data[0]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'article_link': 'https://www.theonion.com/thirtysomething-scientists-unveil-doomsday-clock-of-hai-1819586205',\n",
              " 'headline': 'thirtysomething scientists unveil doomsday clock of hair loss',\n",
              " 'is_sarcastic': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K7g7y52jd-i"
      },
      "source": [
        "#Creating our X variable\n",
        "vectorizer = TfidfVectorizer(max_features=50, use_idf=False)\n",
        "headlines = [i['headline'] for i in data]\n",
        "X = vectorizer.fit_transform(headlines).toarray()\n",
        "\n",
        "#Creating our y variable\n",
        "y = np.ravel([i['is_sarcastic'] for i in data])\n",
        "\n",
        "#Creating a train and test split\n",
        "X_train, X_test, y_train, y_test = tts(X, y, test_size = 0.2, random_state = 1693)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQTIoXv5jwFd"
      },
      "source": [
        "#Now we're going to build the model with its layers\n",
        "\n",
        "#Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "#Add the input layer\n",
        "model.add(Dense(24, activation = 'softmax', input_shape = (50,)))\n",
        "\n",
        "#Add first hidden layer\n",
        "model.add(Dense(12, activation = 'softmax'))\n",
        "\n",
        "#Add second hidden layer\n",
        "model.add(Dense(8, activation = 'softmax'))\n",
        "\n",
        "#Add output layer\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3Htwaq_jzUL",
        "outputId": "fd116d82-dbbd-448a-d004-8162e1c5710e"
      },
      "source": [
        "#Now we're going to compile the model\n",
        "#Our loss function is binary crossentropy\n",
        "#Our optimizer is adam\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', \n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy', 'mse'])\n",
        "\n",
        "#We're going to also fit the model\n",
        "#The batch size will be 224 to get ~100 iterations per epoch\n",
        "model.fit(X_train, y_train, epochs = 100,\n",
        "          batch_size = 224, verbose = 1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "103/103 [==============================] - 1s 2ms/step - loss: 0.7099 - accuracy: 0.4780 - mse: 0.2583\n",
            "Epoch 2/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.4780 - mse: 0.2516\n",
            "Epoch 3/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.5133 - mse: 0.2498\n",
            "Epoch 4/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5220 - mse: 0.2493\n",
            "Epoch 5/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5220 - mse: 0.2488\n",
            "Epoch 6/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.5220 - mse: 0.2472\n",
            "Epoch 7/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6779 - accuracy: 0.5710 - mse: 0.2424\n",
            "Epoch 8/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6888 - mse: 0.2314\n",
            "Epoch 9/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.7128 - mse: 0.2161\n",
            "Epoch 10/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.7133 - mse: 0.2029\n",
            "Epoch 11/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7141 - mse: 0.1945\n",
            "Epoch 12/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7136 - mse: 0.1899\n",
            "Epoch 13/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7202 - mse: 0.1873\n",
            "Epoch 14/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7235 - mse: 0.1857\n",
            "Epoch 15/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7238 - mse: 0.1848\n",
            "Epoch 16/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7259 - mse: 0.1841\n",
            "Epoch 17/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7262 - mse: 0.1836\n",
            "Epoch 18/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7254 - mse: 0.1832\n",
            "Epoch 19/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7264 - mse: 0.1830\n",
            "Epoch 20/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7262 - mse: 0.1826\n",
            "Epoch 21/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7265 - mse: 0.1824\n",
            "Epoch 22/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7267 - mse: 0.1822\n",
            "Epoch 23/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7272 - mse: 0.1820\n",
            "Epoch 24/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7264 - mse: 0.1819\n",
            "Epoch 25/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7271 - mse: 0.1816\n",
            "Epoch 26/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7264 - mse: 0.1815\n",
            "Epoch 27/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7275 - mse: 0.1814\n",
            "Epoch 28/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7271 - mse: 0.1812\n",
            "Epoch 29/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7275 - mse: 0.1811\n",
            "Epoch 30/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7278 - mse: 0.1809\n",
            "Epoch 31/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7276 - mse: 0.1808\n",
            "Epoch 32/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7280 - mse: 0.1806\n",
            "Epoch 33/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7285 - mse: 0.1805\n",
            "Epoch 34/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7270 - mse: 0.1803\n",
            "Epoch 35/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7279 - mse: 0.1802\n",
            "Epoch 36/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7275 - mse: 0.1801\n",
            "Epoch 37/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7283 - mse: 0.1799\n",
            "Epoch 38/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7281 - mse: 0.1798\n",
            "Epoch 39/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7285 - mse: 0.1797\n",
            "Epoch 40/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7281 - mse: 0.1795\n",
            "Epoch 41/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7282 - mse: 0.1794\n",
            "Epoch 42/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7279 - mse: 0.1793\n",
            "Epoch 43/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7285 - mse: 0.1792\n",
            "Epoch 44/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7287 - mse: 0.1791\n",
            "Epoch 45/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7293 - mse: 0.1790\n",
            "Epoch 46/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7286 - mse: 0.1788\n",
            "Epoch 47/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7286 - mse: 0.1788\n",
            "Epoch 48/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7289 - mse: 0.1787\n",
            "Epoch 49/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7289 - mse: 0.1786\n",
            "Epoch 50/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7294 - mse: 0.1784\n",
            "Epoch 51/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7289 - mse: 0.1784\n",
            "Epoch 52/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7287 - mse: 0.1783\n",
            "Epoch 53/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7298 - mse: 0.1782\n",
            "Epoch 54/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7297 - mse: 0.1781\n",
            "Epoch 55/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7295 - mse: 0.1780\n",
            "Epoch 56/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7295 - mse: 0.1780\n",
            "Epoch 57/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7296 - mse: 0.1779\n",
            "Epoch 58/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7296 - mse: 0.1778\n",
            "Epoch 59/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7299 - mse: 0.1777\n",
            "Epoch 60/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7299 - mse: 0.1777\n",
            "Epoch 61/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7301 - mse: 0.1776\n",
            "Epoch 62/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7299 - mse: 0.1775\n",
            "Epoch 63/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7297 - mse: 0.1774\n",
            "Epoch 64/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7300 - mse: 0.1774\n",
            "Epoch 65/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7301 - mse: 0.1773\n",
            "Epoch 66/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7295 - mse: 0.1773\n",
            "Epoch 67/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7299 - mse: 0.1771\n",
            "Epoch 68/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7306 - mse: 0.1771\n",
            "Epoch 69/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7298 - mse: 0.1770\n",
            "Epoch 70/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7306 - mse: 0.1770\n",
            "Epoch 71/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7303 - mse: 0.1769\n",
            "Epoch 72/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7300 - mse: 0.1769\n",
            "Epoch 73/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7304 - mse: 0.1768\n",
            "Epoch 74/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7298 - mse: 0.1767\n",
            "Epoch 75/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7307 - mse: 0.1766\n",
            "Epoch 76/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7300 - mse: 0.1765\n",
            "Epoch 77/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7302 - mse: 0.1765\n",
            "Epoch 78/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7313 - mse: 0.1764\n",
            "Epoch 79/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7307 - mse: 0.1764\n",
            "Epoch 80/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7306 - mse: 0.1764\n",
            "Epoch 81/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7305 - mse: 0.1763\n",
            "Epoch 82/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7309 - mse: 0.1762\n",
            "Epoch 83/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.7313 - mse: 0.1762\n",
            "Epoch 84/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7313 - mse: 0.1761\n",
            "Epoch 85/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7316 - mse: 0.1761\n",
            "Epoch 86/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7309 - mse: 0.1761\n",
            "Epoch 87/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7312 - mse: 0.1760\n",
            "Epoch 88/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7306 - mse: 0.1759\n",
            "Epoch 89/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7319 - mse: 0.1758\n",
            "Epoch 90/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7314 - mse: 0.1758\n",
            "Epoch 91/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7311 - mse: 0.1758\n",
            "Epoch 92/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7305 - mse: 0.1757\n",
            "Epoch 93/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7318 - mse: 0.1757\n",
            "Epoch 94/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7326 - mse: 0.1756\n",
            "Epoch 95/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7326 - mse: 0.1755\n",
            "Epoch 96/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7318 - mse: 0.1755\n",
            "Epoch 97/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7307 - mse: 0.1755\n",
            "Epoch 98/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7326 - mse: 0.1754\n",
            "Epoch 99/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7329 - mse: 0.1754\n",
            "Epoch 100/100\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7325 - mse: 0.1754\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fadc04ab910>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6Er-9aKkGLa",
        "outputId": "2f88dc29-f30b-4688-eaeb-8f8e5d096217"
      },
      "source": [
        "#Next, we'll test the model on the test dataset we set aside\n",
        "\n",
        "#Prediction on the X_test data, round each to an integer (either 0 or 1)\n",
        "y_pred = np.around(model.predict(X_test))\n",
        "\n",
        "#We're going to now look at the accuracy and loss\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(score)\n",
        "\n",
        "#We'll print precision and recall too\n",
        "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred)}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179/179 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.7145 - mse: 0.1813\n",
            "[0.5368219614028931, 0.7145352959632874, 0.18131062388420105]\n",
            "Precision: 0.6639751552795031\n",
            "Recall: 0.7947955390334572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7LkWwCskGYa",
        "outputId": "b3454920-6c5a-4005-eba0-bd9d66de3570"
      },
      "source": [
        "#Now we're going to make a confusion matri\n",
        "#The rows are the known labels, the columns are the predicted labels\n",
        "matrix = cm(y_test, y_pred)\n",
        "df = pd.DataFrame(columns = ['', 'is_sarcastic', 'not_sarcastic'])\n",
        "df.loc[len(df)] = ['is_sarcastic', matrix[0][0], matrix[0][1]]\n",
        "df.loc[len(df)] = ['not_sarcastic', matrix[1][0], matrix[1][1]]\n",
        "print(df)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 is_sarcastic not_sarcastic\n",
            "0   is_sarcastic         1952          1082\n",
            "1  not_sarcastic          552          2138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULuuSIkKkJ5l"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}